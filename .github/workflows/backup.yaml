name: supabase-backup

on:
  push:
    branches: [main, dev]
  workflow_dispatch:
  schedule:
    - cron: "0 0 * * *"

env:
  BACKUP_ENABLED: true
  BACKUP_DIR: backups

jobs:
  run_db_backup:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    env:
      SUPABASE_DB_URL: ${{ secrets.SUPABASE_DB_URL }}
      BACKUP_ENABLED: ${{ vars.BACKUP_ENABLED }}
    steps:
      - name: Check if backups are enabled
        run: |
          if [ "$BACKUP_ENABLED" != "true" ]; then
            echo "Backups are disabled. Exiting workflow."
            exit 0
          fi

      - name: Checkout repository
        if: env.BACKUP_ENABLED == 'true'
        uses: actions/checkout@v3
        with:
          ref: ${{ github.head_ref || github.ref_name }}
          fetch-depth: 0

      - name: Setup Supabase CLI
        if: env.BACKUP_ENABLED == 'true'
        uses: supabase/setup-cli@v1
        with:
          version: latest

      - name: Setup PostgreSQL client
        if: env.BACKUP_ENABLED == 'true'
        run: |
          sudo apt-get update
          sudo apt-get remove -y postgresql-client 2>/dev/null || true
          sudo apt-get install -y wget ca-certificates
          wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
          echo "deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main" | sudo tee /etc/apt/sources.list.d/pgdg.list
          sudo apt-get update
          sudo apt-get install -y postgresql-client-17

      - name: Setup backup environment
        if: env.BACKUP_ENABLED == 'true'
        run: |
          chmod +x .github/scripts/*.sh
          mkdir -p "$BACKUP_DIR/latest" "$BACKUP_DIR/archive"

      - name: Generate backup timestamp
        if: env.BACKUP_ENABLED == 'true'
        id: timestamp
        run: |
          BACKUP_TIMESTAMP=$(date -u +"%Y-%m-%dT%H-%M-%SZ")
          echo "timestamp=$BACKUP_TIMESTAMP" >> $GITHUB_OUTPUT
          echo "Generated backup timestamp: $BACKUP_TIMESTAMP"

      - name: Detect schemas
        if: env.BACKUP_ENABLED == 'true'
        id: detect-schemas
        run: |
          set +e

          # Source common.sh first for utility functions
          SOURCE_ERROR=$(mktemp)
          if ! source .github/scripts/common.sh 2> "$SOURCE_ERROR"; then
            echo "Error: Failed to source common.sh" >&2
            cat "$SOURCE_ERROR" >&2
            rm -f "$SOURCE_ERROR"
            exit 1
          fi
          rm -f "$SOURCE_ERROR"

          # Source the script and capture any sourcing errors
          if ! source .github/scripts/detect.sh 2> "$SOURCE_ERROR"; then
            echo "Error: Failed to source detect.sh" >&2
            cat "$SOURCE_ERROR" >&2
            rm -f "$SOURCE_ERROR"
            exit 1
          fi
          rm -f "$SOURCE_ERROR"

          SCHEMA_OUTPUT=$(mktemp)
          # Note: We don't capture stderr to a file - let errors show in logs immediately

          echo "Debug: Calling detect_schemas function..." >&2
          echo "Debug: Using PostgreSQL binary: $(get_pg_binary psql)" >&2
          echo "Debug: PostgreSQL binary exists: $([ -f "$(get_pg_binary psql)" ] && echo 'yes' || echo 'no')" >&2
          echo "Debug: Testing PostgreSQL connection..." >&2

          # Run detect_schemas - errors will go to stderr (visible in logs)
          # Capture stdout for processing
          detect_schemas "$SUPABASE_DB_URL" > "$SCHEMA_OUTPUT" || {
            EXIT_CODE=$?
            set -e
            echo "" >&2
            echo "=== Schema Detection Failed (Exit code: $EXIT_CODE) ===" >&2
            echo "" >&2
            echo "=== Captured Standard Output ===" >&2
            if [ -s "$SCHEMA_OUTPUT" ]; then
              cat "$SCHEMA_OUTPUT" >&2
            else
              echo "(Output file is empty)" >&2
            fi
            echo "" >&2
            echo "=== Debug Information ===" >&2
            echo "PostgreSQL client location: $(get_pg_binary psql)" >&2
            echo "PostgreSQL client exists: $([ -f "$(get_pg_binary psql)" ] && echo 'yes' || echo 'no')" >&2
            echo "PostgreSQL client version: $($(get_pg_binary psql) --version 2>&1 || echo 'failed to get version')" >&2
            rm -f "$SCHEMA_OUTPUT"
            exit $EXIT_CODE
          }
          EXIT_CODE=0
          set -e

          echo "Debug: detect_schemas completed successfully" >&2

          SCHEMAS=$(cat "$SCHEMA_OUTPUT" | grep -vE "^(Resolved|Warning)" | grep -E "^[a-zA-Z_][a-zA-Z0-9_]*$")
          rm -f "$SCHEMA_OUTPUT"

          if [ -z "$SCHEMAS" ]; then
            echo "Warning: No schemas detected" >&2
          fi

          echo "schemas<<EOF" >> $GITHUB_OUTPUT
          echo "$SCHEMAS" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

          echo "Detected schemas:"
          echo "$SCHEMAS" | while read schema; do
            [ -n "$schema" ] && echo "  - $schema"
          done

      - name: Create archive directory
        if: env.BACKUP_ENABLED == 'true'
        id: archive
        run: |
          source .github/scripts/backup.sh
          BACKUP_TIMESTAMP="${{ steps.timestamp.outputs.timestamp }}"
          SOURCE_REPO="${{ github.repository }}"
          TRIGGER_EVENT="${{ github.event_name }}"
          COMMIT_SHA="${{ github.sha }}"

          # Create archive directory
          ARCHIVE_PATH=$(create_archive_directory "$BACKUP_DIR" "$BACKUP_TIMESTAMP" "$SOURCE_REPO" "$TRIGGER_EVENT" "${COMMIT_SHA:0:7}")
          echo "archive_path=$ARCHIVE_PATH" >> $GITHUB_OUTPUT
          echo "archive_name=$(basename "$ARCHIVE_PATH")" >> $GITHUB_OUTPUT
          echo "Created archive directory: $ARCHIVE_PATH"

      - name: Backup roles
        if: env.BACKUP_ENABLED == 'true'
        run: |
          source .github/scripts/backup.sh
          ARCHIVE_PATH="${{ steps.archive.outputs.archive_path }}"
          backup_roles "$SUPABASE_DB_URL" "$ARCHIVE_PATH/roles.sql"

      - name: Backup schemas and tables
        if: env.BACKUP_ENABLED == 'true'
        id: backup-schemas
        env:
          BACKUP_MAX_PARALLEL: 8 # Number of parallel table backups per schema
          GLOBAL_MAX_CONNECTIONS: 10 # Total concurrent database connections across all schemas
          # Note: This includes connections for table detection queries, so 10 allows for better parallelism
        run: |
          set +e  # Disable exit on error for parallel execution
          START_TIME=$(date +%s)
          source .github/scripts/common.sh
          source .github/scripts/backup.sh
          set +e  # Re-disable exit on error after sourcing (backup.sh sets -e)

          # Initialize global connection semaphore to limit total concurrent connections
          # Use a fixed semaphore directory that all background jobs can access
          export GLOBAL_SEMAPHORE_DIR="/tmp/backup_semaphore_$$"
          export GLOBAL_MAX_CONNECTIONS="${GLOBAL_MAX_CONNECTIONS:-10}"
          init_global_semaphore
          trap "cleanup_global_semaphore" EXIT

          SCHEMAS="${{ steps.detect-schemas.outputs.schemas }}"

          if [ -z "$SCHEMAS" ]; then
            echo "No schemas detected. Exiting."
            cleanup_global_semaphore
            exit 0
          fi

          # Backup schemas in parallel for better performance
          # Run all schemas in parallel - connection semaphore will limit total connections
          SCHEMA_COUNT=0
          SCHEMA_PIDS=()

          # Get archive path from previous step
          ARCHIVE_PATH="${{ steps.archive.outputs.archive_path }}"

          # Start all schema backups in parallel
          for schema in $SCHEMAS; do
            [ -z "$schema" ] && continue
            
            # Start schema backup in background (all at once)
            (
              set +e
              backup_schema "$SUPABASE_DB_URL" "$schema" "$ARCHIVE_PATH" || {
                echo "Warning: Failed to backup schema $schema" >&2
              }
            ) &
            SCHEMA_PIDS+=($!)
            ((SCHEMA_COUNT++))
          done

          # Wait for all schema backups to complete
          for pid in "${SCHEMA_PIDS[@]}"; do
            wait "$pid" 2>/dev/null || true
          done

          echo "Completed backup for $SCHEMA_COUNT schema(s)"

          # Cleanup semaphore
          cleanup_global_semaphore
          trap - EXIT

          END_TIME=$(date +%s)
          echo "start_time=$START_TIME" >> $GITHUB_OUTPUT
          echo "end_time=$END_TIME" >> $GITHUB_OUTPUT
          set -e  # Re-enable exit on error (after outputs are set)

      - name: Create latest reference
        if: env.BACKUP_ENABLED == 'true'
        run: |
          ARCHIVE_PATH="${{ steps.archive.outputs.archive_path }}"
          ARCHIVE_NAME="${{ steps.archive.outputs.archive_name }}"

          # Try to create symlink from latest to archive
          # If symlink fails (Git doesn't handle symlinks well), copy contents
          rm -rf "$BACKUP_DIR/latest"
          if ln -sf "archive/$ARCHIVE_NAME" "$BACKUP_DIR/latest" 2>/dev/null; then
            echo "Created symlink: latest â†’ archive/$ARCHIVE_NAME"
          else
            # Fallback: copy contents to latest (Git-friendly)
            echo "Creating copy in latest/ (symlink not supported)" >&2
            cp -r "$ARCHIVE_PATH" "$BACKUP_DIR/latest"
            echo "Copied archive contents to latest/"
          fi

      - name: Generate backup summary
        if: env.BACKUP_ENABLED == 'true'
        run: |
          source .github/scripts/backup.sh
          START_TIME="${{ steps.backup-schemas.outputs.start_time }}"
          END_TIME="${{ steps.backup-schemas.outputs.end_time }}"
          BACKUP_TIMESTAMP="${{ steps.timestamp.outputs.timestamp }}"
          ARCHIVE_NAME="${{ steps.archive.outputs.archive_name }}"
          print_backup_summary "$BACKUP_DIR" "$SUPABASE_DB_URL" "$START_TIME" "$END_TIME" "$BACKUP_TIMESTAMP" "$ARCHIVE_NAME"

      - name: Commit backups
        if: env.BACKUP_ENABLED == 'true'
        uses: stefanzweifel/git-auto-commit-action@v4
        with:
          commit_message: "Backup: Supabase database backup - $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
          file_pattern: "backups/**"
          branch: ${{ github.head_ref || github.ref_name }}
